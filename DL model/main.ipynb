{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras.regularizers import l2,l1_l2\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, LeakyReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras.preprocessing.image as image\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4024 images belonging to 2 classes.\n",
      "Found 1006 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2, horizontal_flip=True,vertical_flip=True,\n",
    "                                   fill_mode=\"nearest\", rotation_range=10,brightness_range=[0.8,1.2],width_shift_range=0.1, height_shift_range=0.1)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "direc='C:\\\\Users\\\\HP\\\\.vscode\\\\Python\\\\AI\\\\ML Projects\\\\Datasets\\\\Apple\\\\'\n",
    "Train=train_datagen.flow_from_directory(direc+'train',target_size=(64,64),batch_size=32,class_mode='binary')\n",
    "Validate=validation_datagen.flow_from_directory(direc+'valid',target_size=(64,64),batch_size=32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.engine.input_layer.InputLayer object at 0x000001A22BA886D0> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A22BFF14F0> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A22BFF1CD0> False\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001A22C047D00> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A22C047CD0> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A22C088730> False\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001A22C0A3850> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A22C088C40> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A22C0AC2E0> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A22C0B8460> False\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001A22C0BC7F0> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A22C0B8520> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A22C0C1340> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A22C0BC850> False\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001A22C0CF340> False\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A22C0CF8B0> True\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A22C0CD7C0> True\n",
      "<keras.src.layers.convolutional.conv2d.Conv2D object at 0x000001A22C0CFBB0> True\n",
      "<keras.src.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000001A22C0DBDC0> True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the pre-trained VGG16 model\n",
    "vgg_model = VGG16(input_shape=(64, 64, 3), include_top=False, weights='imagenet')\n",
    "\n",
    "# Freezing some layers so that there weights won't be updated\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "for layer in vgg_model.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Check which layers are trainable\n",
    "for layer in vgg_model.layers:\n",
    "    print(layer, layer.trainable)\n",
    "\n",
    "# Create a custom classification head\n",
    "model = Sequential([\n",
    "    vgg_model,\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.00001, verbose=1)\n",
    "checkpoint=ModelCheckpoint('best_model.h5',monitor='val_loss',mode='min',save_best_only=True,verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.1162 - accuracy: 0.9573\n",
      "Epoch 1: val_loss did not improve from 0.06102\n",
      "126/126 [==============================] - 111s 884ms/step - loss: 0.1162 - accuracy: 0.9573 - val_loss: 0.0719 - val_accuracy: 0.9682 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.0929 - accuracy: 0.9652\n",
      "Epoch 2: val_loss improved from 0.06102 to 0.04785, saving model to best_model.h5\n",
      "126/126 [==============================] - 113s 897ms/step - loss: 0.0929 - accuracy: 0.9652 - val_loss: 0.0479 - val_accuracy: 0.9831 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.0862 - accuracy: 0.9665\n",
      "Epoch 3: val_loss did not improve from 0.04785\n",
      "126/126 [==============================] - 105s 832ms/step - loss: 0.0862 - accuracy: 0.9665 - val_loss: 0.0547 - val_accuracy: 0.9742 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 0.9729\n",
      "Epoch 4: val_loss did not improve from 0.04785\n",
      "126/126 [==============================] - 106s 841ms/step - loss: 0.0749 - accuracy: 0.9729 - val_loss: 0.1071 - val_accuracy: 0.9592 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.0705 - accuracy: 0.9744\n",
      "Epoch 5: val_loss did not improve from 0.04785\n",
      "126/126 [==============================] - 105s 831ms/step - loss: 0.0705 - accuracy: 0.9744 - val_loss: 0.0878 - val_accuracy: 0.9612 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.0565 - accuracy: 0.9814\n",
      "Epoch 6: val_loss improved from 0.04785 to 0.02856, saving model to best_model.h5\n",
      "126/126 [==============================] - 106s 844ms/step - loss: 0.0565 - accuracy: 0.9814 - val_loss: 0.0286 - val_accuracy: 0.9911 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.0665 - accuracy: 0.9779\n",
      "Epoch 7: val_loss did not improve from 0.02856\n",
      "126/126 [==============================] - 106s 842ms/step - loss: 0.0665 - accuracy: 0.9779 - val_loss: 0.0462 - val_accuracy: 0.9851 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9786\n",
      "Epoch 8: val_loss did not improve from 0.02856\n",
      "126/126 [==============================] - 104s 823ms/step - loss: 0.0601 - accuracy: 0.9786 - val_loss: 0.0860 - val_accuracy: 0.9672 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.0486 - accuracy: 0.9816\n",
      "Epoch 9: val_loss did not improve from 0.02856\n",
      "126/126 [==============================] - 105s 837ms/step - loss: 0.0486 - accuracy: 0.9816 - val_loss: 0.0477 - val_accuracy: 0.9781 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "126/126 [==============================] - ETA: 0s - loss: 0.0495 - accuracy: 0.9816\n",
      "Epoch 10: val_loss improved from 0.02856 to 0.02226, saving model to best_model.h5\n",
      "126/126 [==============================] - 104s 829ms/step - loss: 0.0495 - accuracy: 0.9816 - val_loss: 0.0223 - val_accuracy: 0.9930 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history1=model.fit(x=Train,validation_data=Validate,epochs=10,callbacks=[early_stopping,checkpoint,reduce_lr],verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
